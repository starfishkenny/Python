{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "overall-variable",
   "metadata": {},
   "source": [
    "### 빅데이터분석기사 실기 준비\n",
    "#### KOOC 컨텐츠를 활용한 시험 준비 계획\n",
    "*  파이썬으로 배우는 프로그래밍 기초 (김문주 교수님)\n",
    "*  인공지능 코딩을 위한 실용 파이썬 (권영선 교수님)\n",
    "*  뭔가 이번 시험은 맛보기로 봐야할 듯,,, "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "still-terry",
   "metadata": {},
   "source": [
    "#### 필답형 준비\n",
    "Reference: https://deepcell.kr/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lovely-profit",
   "metadata": {},
   "source": [
    "#### 작업형 준비\n",
    "Reference: https://deepcell.kr/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "packed-quantum",
   "metadata": {},
   "source": [
    "#### 작업형 제2유형 베이스라인 (출처: https://deepcell.kr/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breeding-persian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 준비\n",
    "\n",
    "import os\n",
    "\n",
    "from time import time\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from pandas import read_csv, set_option\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, RepeatedStratifiedKFold #, KFold\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, StandardScaler\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "\n",
    "# model\n",
    "\n",
    "# linear\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "\n",
    "\n",
    "# non-linear\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "\n",
    "# ensemble\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "\n",
    "# Neural lNetwork\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "\n",
    "# XGBoost\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "\n",
    "# metric\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "\n",
    "\n",
    "# utils\n",
    "\n",
    "from sklearn.utils import resample, shuffle # imbalanced data를 up/down sampling할 때 사용\n",
    "\n",
    "\n",
    "\n",
    "# b) 데이터 로드\n",
    "\n",
    "data_dir = 'data'\n",
    "\n",
    "X_train_file = os.path.join(data_dir, 'X_train.csv')\n",
    "\n",
    "y_train_file = os.path.join(data_dir, 'y_train.csv')\n",
    "\n",
    "X_test_file = os.path.join(data_dir, 'X_test.csv')\n",
    "\n",
    "\n",
    "\n",
    "X_train_df = read_csv(X_train_file)\n",
    "\n",
    "y_train_df = read_csv(y_train_file)\n",
    "\n",
    "X_test_df = read_csv(X_test_file)\n",
    "\n",
    "\n",
    "\n",
    "# 2. 데이터 분석(시각화는 생략)\n",
    "\n",
    "# 기술 통계(descriptive statistics)\n",
    "\n",
    "\n",
    "\n",
    "print(X_train_df.shape)\n",
    "\n",
    "print(X_train_df.info())\n",
    "\n",
    "print(X_train_df.describe())\n",
    "\n",
    "print(y_train_df.groupby('gender').size())\n",
    "\n",
    "\n",
    "\n",
    "print(X_test_df.info())\n",
    "\n",
    "print(X_test_df.describe())\n",
    "\n",
    "\n",
    "\n",
    "# 3 제출 파일 만들기 : 시험을 위한 코드(필수 암기)\n",
    "\n",
    "exam_num = '0000'\n",
    "\n",
    "submit_file = exam_num + '.csv'\n",
    "\n",
    "\n",
    "\n",
    "col_1_name = 'cust_id'\n",
    "\n",
    "col_2_name = 'gender'\n",
    "\n",
    "default_value = 0.5 # 임의의 값을 대입하여 출력하는 경우 0점이라고 합니다.\n",
    "\n",
    "\n",
    "\n",
    "col_1 = X_test_df.cust_id\n",
    "\n",
    "test_row_num = len(X_test_df)\n",
    "\n",
    "col_2  = np.full(test_row_num, default_value)\n",
    "\n",
    "\n",
    "\n",
    "submit = pd.DataFrame({col_1_name:col_1, col_2_name:col_2})\n",
    "\n",
    "submit.to_csv(submit_file, index=False)\n",
    "\n",
    "\n",
    "\n",
    "# 4. 데이터 준비\n",
    "\n",
    "\n",
    "\n",
    "# a) 데이터 정제 : \n",
    "\n",
    "#   - 결측데이터 처리(환불금액이 없는 데이터를 0으로 변경) \n",
    "\n",
    "#   - 이상데이터 제거(총구매액이 음수인 데이터를 제거 하려 하였으나 \n",
    "\n",
    "#     총구매액이 음수인 데이터가 테스트 데이터에도 있어서 그대로 트레이닝\n",
    "\n",
    "\n",
    "\n",
    "train_df = pd.merge(X_train_df, y_train_df)\n",
    "\n",
    "# train_df = train_df[train_df['총구매액']>=0]\n",
    "\n",
    "\n",
    "\n",
    "train_df['환불금액'] = train_df['환불금액'].fillna(0)\n",
    "\n",
    "X_test_df['환불금액'] = X_test_df['환불금액'].fillna(0)\n",
    "\n",
    "\n",
    "\n",
    "X = train_df.drop(['cust_id', 'gender'], axis=1)\n",
    "\n",
    "y = train_df.gender\n",
    "\n",
    "X_test = X_test_df.drop(['cust_id'], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# b) 데이터 변환\n",
    "\n",
    "#  - 범주형 데이터 인코딩(One-Hot Encoding) : 선형 모델의 경우 원핫 인코딩을 해야함, 결정나무 계열은 별 차이 없음\n",
    "\n",
    "#  - 스케일 변환(Standard or MinMax) : 스케일 변환은 데이터 분리와 관련이 있으므로 파이프라인과 함께 코딩\n",
    "\n",
    "\n",
    "\n",
    "# 인코딩\n",
    "\n",
    "X_encoded = pd.get_dummies(X)\n",
    "\n",
    "X_test_encoded = pd.get_dummies(X_test)\n",
    "\n",
    "\n",
    "\n",
    "lack_cols = set(X_encoded.columns) - set(X_test_encoded.columns)\n",
    "\n",
    "remain_cols = set(X_test_encoded.columns) - set(X_encoded.columns)\n",
    "\n",
    "\n",
    "\n",
    "print(lack_cols)\n",
    "\n",
    "print(remain_cols)\n",
    "\n",
    "\n",
    "\n",
    "# 부족한 컬럼은 0을 값으로 하는 컬럼으로 새로 만들기\n",
    "\n",
    "for col in lack_cols:\n",
    "\n",
    "    X_test_encoded[col] = 0\n",
    "\n",
    "\n",
    "\n",
    "# 남는 컬럼(테스트 데이터셋에만 있는 컬럼)은 제거\n",
    "\n",
    "for col in remain_cols:\n",
    "\n",
    "    X_test_encoded.drop(col, axis=1)\n",
    "\n",
    "\n",
    "\n",
    "### 준비되 데이터 : 인코딩\n",
    "\n",
    "# 전체 트레이닝 데이터와 라벨 : X_encoded, y\n",
    "\n",
    "# 전체 테스트 데이터 : X_test_encoded\n",
    "\n",
    "\n",
    "\n",
    "# 5. 알고리즘 평가 : 성능이 좋은 알고리즘 찾기\n",
    "\n",
    "\n",
    "\n",
    "# a) 테스트 옵션(변수) 설정\n",
    "\n",
    "seed = 1 # random seed\n",
    "\n",
    "num_fold = 5\n",
    "\n",
    "num_repeat = 1\n",
    "\n",
    "scoring = 'roc_auc'\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=num_fold, n_repeats=num_repeat, random_state=seed)\n",
    "\n",
    "\n",
    "\n",
    "# b) 데이터 분리 : 트레이닝 데이터와 검증 데이터 분리\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_encoded, y, test_size=0.2, random_state=seed)\n",
    "\n",
    "\n",
    "\n",
    "# 데이터를 표준 스케일 변환 후 트레이닝\n",
    "\n",
    "start_time = time()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "#scaler = MinMaxScaler()\n",
    "\n",
    "pipelines = []\n",
    "\n",
    "pipelines.append(('ScaledLR', Pipeline([('Scaler', scaler), ('LR', LogisticRegression(solver='liblinear'))])))\n",
    "\n",
    "pipelines.append(('ScaledLDA', Pipeline([('Scaler', scaler), ('LDA', LinearDiscriminantAnalysis())])))\n",
    "\n",
    "pipelines.append(('ScaledKNN', Pipeline([('Scaler', scaler), ('KNN', KNeighborsClassifier())])))\n",
    "\n",
    "pipelines.append(('ScaledNB', Pipeline([('Scaler', scaler), ('NB', GaussianNB())])))\n",
    "\n",
    "pipelines.append(('ScaledSVM', Pipeline([('Scaler', scaler),('SVM', SVC(gamma='auto'))])))\n",
    "\n",
    "# pipelines.append(('ScaledSVM', Pipeline([('Scaler', scaler),('SVM', SVC(gamma='auto', class_weight='balanced', probability=True))])))\n",
    "\n",
    "pipelines.append(('CART', Pipeline([('CART', DecisionTreeClassifier())])))\n",
    "\n",
    "# ensemble\n",
    "\n",
    "pipelines.append(('AB', Pipeline([('AB', AdaBoostClassifier())])))\n",
    "\n",
    "pipelines.append(('GBM', Pipeline([('GBM', GradientBoostingClassifier())])))\n",
    "\n",
    "pipelines.append(('RF', Pipeline([('RF', RandomForestClassifier())])))\n",
    "\n",
    "pipelines.append(('ET', Pipeline([('ET', ExtraTreesClassifier())])))\n",
    "\n",
    "\n",
    "\n",
    "results = []\n",
    "\n",
    "names = []\n",
    "\n",
    "for name, model in pipelines:\n",
    "\n",
    "    cv_results = cross_val_score(model, X_train, y_train, cv=cv, scoring=scoring)\n",
    "\n",
    "    # cv_results = cross_val_score(model, upsampled_X, upsampled_y, cv=cv, scoring=scoring)\n",
    "\n",
    "    # cv_results = cross_val_score(model, downsampled_X, downsampled_y, cv=cv, scoring=scoring)\n",
    "\n",
    "    \n",
    "\n",
    "    results.append(cv_results)\n",
    "\n",
    "    names.append(name)\n",
    "\n",
    "    \n",
    "\n",
    "means = []\n",
    "\n",
    "stds = []\n",
    "\n",
    "for result in results:\n",
    "\n",
    "    means.append(result.mean())\n",
    "\n",
    "    stds.append(result.std())\n",
    "\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame({'mean': means, 'std': stds, 'name':names})\n",
    "\n",
    "print('time : ', time()-start_time)\n",
    "\n",
    "print(results_df.sort_values('mean', axis=0, ascending=False))\n",
    "\n",
    "\n",
    "\n",
    "# 6. 최선의 모델 선택, 위 결과중 가장 성능이 좋은 모델을 선택하여 검증\n",
    "\n",
    "# valid data로 검증\n",
    "\n",
    "\n",
    "\n",
    "# best_model = AdaBoostClassifier()\n",
    "\n",
    "# best_model = GradientBoostingClassifier()\n",
    "\n",
    "best_model = Pipeline([('Scaler', scaler), ('LR', LogisticRegression(solver='liblinear'))])\n",
    "\n",
    "# best_model = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "# best_model = ExtraTreesClassifier(n_estimators=200)\n",
    "\n",
    "# best_model = SVC(gamma='auto', probability=True)\n",
    "\n",
    "# best_model = LinearDiscriminantAnalysis()\n",
    "\n",
    "\n",
    "\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "best_predict = best_model.predict_proba(X_valid)\n",
    "\n",
    "best_score = roc_auc_score(y_valid, best_predict[:, 1] )\n",
    "\n",
    "print('roc auc score : %f' %(best_score))\n",
    "\n",
    "\n",
    "\n",
    "# 7. 전체 트레이닝 데이터를 이용하여 다시 트레이닝 및 예측\n",
    "\n",
    "# 제출용 : 전체 trainind data로 트레이닝을 하고 예측\n",
    "\n",
    "best_model.fit(X_encoded, y)\n",
    "\n",
    "submit_predict = best_model.predict_proba(X_test_encoded)\n",
    "\n",
    "\n",
    "\n",
    "# 8. 제출 파일 작성 및 제출\n",
    "\n",
    "submit['gender'] = submit_predict[:, 1]\n",
    "\n",
    "submit.to_csv(submit_file, index=False)\n",
    "\n",
    "\n",
    "\n",
    "# 제출 전 파일 확인\n",
    "\n",
    "submit_df = read_csv(submit_file)\n",
    "\n",
    "print(submit_df.head(20)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

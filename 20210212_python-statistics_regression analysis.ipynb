{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. 회귀분석\n",
    "### - 단순회귀모형\n",
    "### - 중회귀모형\n",
    "### - 모형의 선택\n",
    "### - 모형의 타당성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 회귀분석에 의해 변수 사이의 인과관계가 명확해지고 한 변수가 다른 변수에 끼치는 영향을 추정할 수 있음\n",
    "* 모형 $\\rightarrow$ 현실 세계에서 발생하는 복잡한 현상의 특징을 잘 포착하여 단순화한 것\n",
    "* 회귀분석의 목적 $\\rightarrow$ 복잡한 현상을 사람이 이해할 수 있을 정도의 간단한 구조로 충분히 설명할 수 있는 모형을 찾는 것이 목적"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기존에 사용했던 라이브러리에 statsmodels를 추가\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "%precision 3\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quiz</th>\n",
       "      <th>final_test</th>\n",
       "      <th>sleep_time</th>\n",
       "      <th>school_method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.2</td>\n",
       "      <td>67</td>\n",
       "      <td>7.2</td>\n",
       "      <td>bus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.2</td>\n",
       "      <td>71</td>\n",
       "      <td>7.9</td>\n",
       "      <td>bicycle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>19</td>\n",
       "      <td>5.3</td>\n",
       "      <td>bus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>35</td>\n",
       "      <td>6.8</td>\n",
       "      <td>walk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.5</td>\n",
       "      <td>35</td>\n",
       "      <td>7.5</td>\n",
       "      <td>walk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   quiz  final_test  sleep_time school_method\n",
       "0   4.2          67         7.2           bus\n",
       "1   7.2          71         7.9       bicycle\n",
       "2   0.0          19         5.3           bus\n",
       "3   3.0          35         6.8          walk\n",
       "4   1.5          35         7.5          walk"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 시용할 데이터 불러오기\n",
    "df = pd.read_csv(r'E:\\jupyter\\누구나 파이썬 통계분석\\ch12_scores_reg.csv')\n",
    "n = len(df)\n",
    "print(n)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 단순회귀모형\n",
    "* 회귀분석(regression analysis) $\\rightarrow$ 인과관계가 의심되는 복수의 변수를 사용하여 어느 변수로부터 다른 변수의 값을 예측하는 기법\n",
    "  - 원인이 되는 변수 $\\rightarrow$ 설명변수(explanatory variable) (= 독립변수; independent variable)\n",
    "  - 결과가 되는 변수 $\\rightarrow$ 반응변수(response variable) (= 종속변수; dependent variable)\n",
    "* 단순회귀모형(simple regression model) $\\rightarrow$ 설명변수와 반응변수가 1개씩인 가장 단순한 모델\n",
    "* 회귀분석에서의 가설\n",
    "  - $y = {\\beta_0} + {\\beta_1{x}}$를 가정\n",
    "  - 그러나 데이터는 직선과 완전히 일치하지는 않음\n",
    "  - 기본적인 관계는 직선상에 있다고 생각하고, 다른 요인에 관해서는 예측할 수 없는 확률적인 것이라고 생각\n",
    "  - 예측할 수 없는 부분을 오차항(error term)이라고 함 $\\rightarrow$ $\\epsilon_i$\n",
    "  - 다시... $Y_i = {\\beta_0} + {\\beta_1{x}} + \\epsilon_i$  $(i=1,2,\\dots,n)$\n",
    "  - 회귀분석에서는 추가적으로 두 가지를 가정\n",
    "    + 설명변수가 확률변수는 아니다\n",
    "    + $\\epsilon_i$는 서로 독립이고 $N(0,\\sigma^2)$을 따른다\n",
    "  - 위 가정에 의해 확률변수 $Y_i$는 서로 독립이고 $N({\\beta_0} + {\\beta_1}{x_i}, \\sigma^2$을 따르는 것을 알 수 있음\n",
    "  - 회귀분석은 이러한 가정을 기초로 표본인 $(x_1,Y_1),(x_2,Y_2),\\dots,(x_n,Y_n)$으로부터 모수 $\\beta_0$과 $\\beta_1$을 추정함\n",
    "  - 회귀직선(regression line): $\\beta_0$과 $\\beta_1$의 추정값 $\\hat{\\beta_0}$과 $\\hat{\\beta_1}$에 의해 생성되는 직선 $\\rightarrow$ $y = \\hat{\\beta_0} + \\hat{\\beta_1}{x}$ \n",
    "  - $\\hat{\\beta_0}$과 $\\hat{\\beta_1}$은 회귀계수(regression coefficient)라고 함\n",
    "* statsmodels에 의한 회귀분석\n",
    "  - smf.ols 함수를 활용하여 설명변수와 반응변수의 관계를 나타낸 문자열과 DataFrame을 전달하고, 추가로 fit 메서드를 호출하여 실행할 수 있음\n",
    "    + OLS = 최소제곱법(Ordinary Least Squares)\n",
    "* 회귀계수\n",
    "  - 점추정\n",
    "    + 추정값이 생성한 직선 $y = \\hat{\\beta_0} + \\hat{\\beta_1}{x}$, 즉 회귀직선은 데이터 $(x_1,y_1),(x_2,y_2),\\dots,(x_n,y_n)$에 가장 잘 들어맞는 직선\n",
    "    + '데이터에 가장 잘 들어맞는 직선' $\\rightarrow$ $x_i$로부터 예측된 모형의 예측값(predicted value) $\\hat{y_i} = \\hat{\\beta_0} + \\hat{\\beta_1}x_i$와 실제의 데이터 $y_i$의 차이가 가장 작은 직선\n",
    "    + 엄밀하게는 $y_i - \\hat{y_i}$의 차이를 잔차(residual), 그 제곱합인 잔차제곱합(residual sum of squares; RSS) $\\sum_i^n{\\hat{\\epsilon^2}}$이 더욱 작은 직선으로서 정의\n",
    "    + 잔차제곱합을 최소화하는 $\\hat{\\beta_0}$과 $\\hat{\\beta_1}$을 구하는 방법을 최소제곱법이라고 함\n",
    "    + 최소제곱법으로 구한 $\\hat{\\beta_0}$과 $\\hat{\\beta_1}$은 $\\beta_0$과 $\\beta_1$의 불편일치추정량이 됨\n",
    "  - 구간추정\n",
    "    + $\\beta_0$과 $\\beta_1$의 구간추정 $\\rightarrow$ $\\hat{\\beta_0}$과 $\\hat{\\beta_1}$의 표준오차가 필요\n",
    "    + $\\hat{\\beta_0}$과 $\\hat{\\beta_1}$의 표준오차를 구하는 것은 복잡함\n",
    "    + 결과만 기록하면 각각 $\\sqrt{{C_0}{\\hat{\\sigma^2}}}$과 $\\sqrt{{C_1}{\\hat{\\sigma^2}}}$이 됨\n",
    "    + 다만 $(XX^T)^{-1}$의 대각성분의 첫 번째가 $C_0$, 두 번째가 $C_1$이 됨\n",
    "  - t검정\n",
    "    + 회귀계수에 대한 가설검정\n",
    "    + 귀무가설: $\\beta_1 = 0$\n",
    "    + 대립가설: $\\beta_1 \\neq 0$\n",
    "    + $\\beta_1$에 대해서도 동일한 가설검정을 고려하겠지만, $\\beta_1$에 대한 가설검정에는 중요한 의미가 있음\n",
    "    + $\\beta_1 = 0$인 경우, $y_i = {\\beta_0} + 0 \\times x_i + {\\epsilon_i} = \\beta_0 + {\\epsilon_i}$\n",
    "    + 위와 같을 때, 설명변수가 반응변수에 전혀 영향을 끼치지 않는 모형이 되므로, 귀무가설이 기각되어 $\\beta_1 \\neq 0$이라는 결론을 얻게 됨\n",
    "    + 따라서 설명변수가 반응변수에 영향을 끼치지 않는다고 주장할 수 있게 됨\n",
    "    + 이 가설검정의 검정통계량은 $t = {{\\hat{\\beta_1} - \\beta_1} \\over {\\sqrt{{\\sigma^2}C_1}}}$\n",
    "    + t도 역시 잔차의 제약으로부터 자유도가 n-2인 t분포를 따른다. 더 나아가 귀무가설은 $\\beta_1 = 0$이므로 $t = {{\\hat{\\beta_1}} \\over {\\sqrt{{\\sigma^2}C_1}}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 쪽지시험의 평균 점수: 설명변수, 기말고사 점수: 반응변수\n",
    "x = np.array(df['quiz'])\n",
    "y = np.array(df['final_test'])\n",
    "p = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 산점도와 회귀직선 그리기\n",
    "poly_fit = np.polyfit(x,y,1)\n",
    "poly_1d = np.poly1d(poly_fit)\n",
    "xs = np.linspace(x.min(), x.max())\n",
    "ys = poly_1d(xs)\n",
    "\n",
    "fig = plt.figure(figsize=(10,6))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_xlabel('quiz')\n",
    "ax.set_ylabel('final test')\n",
    "ax.plot(xs, ys, color='gray', label=f'{poly_fit[1]:.2f}+{poly_fit[0]:.2f}x')\n",
    "ax.scatter(x,y)\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>final_test</td>    <th>  R-squared:         </th> <td>   0.676</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.658</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   37.61</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 19 Feb 2021</td> <th>  Prob (F-statistic):</th> <td>8.59e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>20:15:55</td>     <th>  Log-Likelihood:    </th> <td> -76.325</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    20</td>      <th>  AIC:               </th> <td>   156.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    18</td>      <th>  BIC:               </th> <td>   158.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   23.6995</td> <td>    4.714</td> <td>    5.028</td> <td> 0.000</td> <td>   13.796</td> <td>   33.603</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>quiz</th>      <td>    6.5537</td> <td>    1.069</td> <td>    6.133</td> <td> 0.000</td> <td>    4.309</td> <td>    8.799</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 2.139</td> <th>  Durbin-Watson:     </th> <td>   1.478</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.343</td> <th>  Jarque-Bera (JB):  </th> <td>   1.773</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.670</td> <th>  Prob(JB):          </th> <td>   0.412</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.422</td> <th>  Cond. No.          </th> <td>    8.32</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:             final_test   R-squared:                       0.676\n",
       "Model:                            OLS   Adj. R-squared:                  0.658\n",
       "Method:                 Least Squares   F-statistic:                     37.61\n",
       "Date:                Fri, 19 Feb 2021   Prob (F-statistic):           8.59e-06\n",
       "Time:                        20:15:55   Log-Likelihood:                -76.325\n",
       "No. Observations:                  20   AIC:                             156.7\n",
       "Df Residuals:                      18   BIC:                             158.6\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     23.6995      4.714      5.028      0.000      13.796      33.603\n",
       "quiz           6.5537      1.069      6.133      0.000       4.309       8.799\n",
       "==============================================================================\n",
       "Omnibus:                        2.139   Durbin-Watson:                   1.478\n",
       "Prob(Omnibus):                  0.343   Jarque-Bera (JB):                1.773\n",
       "Skew:                           0.670   Prob(JB):                        0.412\n",
       "Kurtosis:                       2.422   Cond. No.                         8.32\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OLS\n",
    "formula = 'final_test ~ quiz'\n",
    "result = smf.ols(formula, df).fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 각 행은 다음에 관한 분석 결과\n",
    "  - Intercept: 절편 $\\beta_0$\n",
    "  - quiz: 기울기 $\\beta_1$\n",
    "* 각 열은 다음을 나타냄\n",
    "  - coef: 회귀계수의 추정값\n",
    "  - std err: 추정값의 표준차\n",
    "  - t: 회귀계수에 관한 t검정통계량\n",
    "  - P>$\\left\\lvert{t}\\right\\rvert$: 검정통계량의 p값\n",
    "  - [0.025와 0.975]: 회귀계수의 95% 신뢰구간"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1. , 4.2],\n",
       "       [1. , 7.2],\n",
       "       [1. , 0. ],\n",
       "       [1. , 3. ],\n",
       "       [1. , 1.5],\n",
       "       [1. , 0.9],\n",
       "       [1. , 1.9],\n",
       "       [1. , 3.5],\n",
       "       [1. , 4. ],\n",
       "       [1. , 5.4],\n",
       "       [1. , 4.2],\n",
       "       [1. , 6.9],\n",
       "       [1. , 2. ],\n",
       "       [1. , 8.8],\n",
       "       [1. , 0.3],\n",
       "       [1. , 6.7],\n",
       "       [1. , 4.2],\n",
       "       [1. , 5.6],\n",
       "       [1. , 1.4],\n",
       "       [1. , 2. ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 최소제곱법으로 추정량 구하기\n",
    "# 선형대수학이나 편미분에 관한 지식이 필요한 부분\n",
    "# 하지만 Numpy로 간단하게 구현\n",
    "X = np.array([np.ones_like(x),x]).T\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-5a011dc8d4d5>:4: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  beta0_hat, beta1_hat = np.linalg.lstsq(X,y)[0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(23.699495346731226, 6.553732606043085)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 최소제곱법 -> np.linalg.lstsq\n",
    "# 첫 번째 인수가 설명변수인 X, 두 번째 인수가 반응변수인 y\n",
    "# 첫 번째 반환값이 구하려는 추정량\n",
    "beta0_hat, beta1_hat = np.linalg.lstsq(X,y)[0]\n",
    "beta0_hat, beta1_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측값과 잔차 계산\n",
    "y_hat = beta0_hat + beta1_hat * x\n",
    "eps_hat = y - y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 잔차 $\\hat{epsilon_i}$는 오차항 $\\epsilon_i$에 대응하고 있기 때문에 잔차의 분산으로부터 모분산 $\\sigma^2$을 추정할 수 있음\n",
    "* 다만, 잔차의 자유도는 회귀계수의 수 $p+1$만큼 감소하여 $n-p-1$이 되므로, 모분산의 불편추정량 $\\hat{\\sigma^2}$은 $n-p-1$로 나누어 계산되는 값\n",
    "* $\\hat{\\sigma^2} = {1 \\over {n-p-1}}{\\sum_i^n(\\hat{\\epsilon_i} - \\bar{\\hat{\\epsilon}})^2} = {1 \\over {n-p-1}}{\\sum_i^n{\\hat{\\epsilon_i^2}}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134.290434734959"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 이 경우 회귀계수의 수가 2이므로 자유도는 n-2\n",
    "s_var = np.var(eps_hat, ddof=p+1)\n",
    "s_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.16546420022873096, 0.008503003686052104)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# C0, C1을 Numpy로 구할 수 있음\n",
    "C0, C1 = np.diag(np.linalg.pinv(np.dot(X.T, X)))\n",
    "C0, C1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.713837012645705, 1.0685841387335373)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# C0, C1을 활용하여 표준오차 계산할 수 있음\n",
    "np.sqrt(s_var*C0), np.sqrt(s_var*C1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 회귀계수의 신뢰구간 \\\n",
    "  회귀계수 $\\beta_0$, $\\beta_1$의 신뢰수준 $100(1-\\alpha)$%의 신뢰구간은 \\\n",
    "  $[{\\hat{\\beta_{i}}} - {t_{\\alpha/2}}(n-2){\\sqrt{\\hat{\\sigma^2}}C_i}, {\\hat{\\beta_{i}}} - {t_{1- \\alpha/2}}(n-2){\\sqrt{\\hat{\\sigma^2}}C_i}] (i=0,1)$ \\\n",
    "  으로 추정됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13.79609127276026, 33.602899420702194)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# beta0_hat의 95% 신뢰구간 구하기\n",
    "rv = stats.t(n-2)\n",
    "\n",
    "lcl = beta0_hat - rv.isf(0.025) * np.sqrt(s_var * C0)\n",
    "hcl = beta0_hat - rv.isf(0.975) * np.sqrt(s_var * C0)\n",
    "lcl, hcl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.308720637125893, 8.798744574960278)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# beta1_hat의 95% 신뢰구간 구하기\n",
    "rv = stats.t(n-2)\n",
    "\n",
    "lcl = beta1_hat - rv.isf(0.025) * np.sqrt(s_var * C1)\n",
    "hcl = beta1_hat - rv.isf(0.975) * np.sqrt(s_var * C1)\n",
    "lcl, hcl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.133099274532023"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = beta1_hat / np.sqrt(s_var * C1)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.590875866687497e-06"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# p깂\n",
    "(1 - rv.cdf(t)) *2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 귀무가설은 기각되어, 쪽지 시험 평균 점수와 기말고사 점수 사이에는 인과관계가 있다고 말할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.027644206440129"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# beta0에 대한 다음의 가설검정도 동일하게 수행\n",
    "t = beta0_hat / np.sqrt(s_var * C0)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.745298393186829e-05"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1 - rv.cdf(t)) *2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.중회귀모형(multiple regression model)\n",
    "* 중회귀모형: 설명변수가 2개 이상인 모형\n",
    "* $y = {\\beta_0} + {{\\beta_1}x_1} + \\dots + {{\\beta_p}x_p}$\n",
    "  - ex) 기말고사라는 반응변수를 설명하기 위해 설명변수로 쪽지 시험 평균 점수와 시험 전날의 수면 시간을 설정 (이 때 p=2)\n",
    "  - $Y = {\\beta_0} + {{\\beta_1}x_{i1}} + {{\\beta_2}x_{i2}} + \\epsilon_i$\n",
    "* 가변수(dummy variable)\n",
    "  - 질적 변수를 어떻게 처리해야할지 생각해볼 필요성 있음\n",
    "  - 질적변수를 변환하여 양적변수와 동일하게 취급할 수 있게 하는 기법을 도입하면 좋을 듯 $\\rightarrow$ 가변수\n",
    "  - 가변수는 0과 1을 취하는 2진 변수로, 변환하고 싶은 질적변수의 카테고리 수에서 하나를 줄인 수만큼 필요\n",
    "  - ex) 통학방법이 '버스','자전거','도보' 세 가지일 때, 가변수를 $x_도보, x_자전거$라고 설정할 수 있음\n",
    "  - 이 가변수에 의해 도보를 $({{x_도보} = 1}, {{x_자전거} = 0})$, 자전거를 $({{x_도보} = 0}, {{x_자전거} = 1})$, 버스를 $({{x_도보} = 0}, {{x_자전거} = 0})$으로 나타낼 수 있음\n",
    "  - 회귀모형은 $Y_i = {\\beta_0} + {{\\beta_1}x_{i1}} + {{\\beta_2}x_{i2}} + {{\\beta_3}x_{i도보}} + {{\\beta_4}x_{i자전거}} + {\\epsilon_i}$가 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>final_test</td>    <th>  R-squared:         </th> <td>   0.756</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.727</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   26.35</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 19 Feb 2021</td> <th>  Prob (F-statistic):</th> <td>6.19e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>20:15:55</td>     <th>  Log-Likelihood:    </th> <td> -73.497</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    20</td>      <th>  AIC:               </th> <td>   153.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    17</td>      <th>  BIC:               </th> <td>   156.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>  <td>   -1.8709</td> <td>   11.635</td> <td>   -0.161</td> <td> 0.874</td> <td>  -26.420</td> <td>   22.678</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>quiz</th>       <td>    6.4289</td> <td>    0.956</td> <td>    6.725</td> <td> 0.000</td> <td>    4.412</td> <td>    8.446</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sleep_time</th> <td>    4.1917</td> <td>    1.778</td> <td>    2.357</td> <td> 0.031</td> <td>    0.440</td> <td>    7.943</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 2.073</td> <th>  Durbin-Watson:     </th> <td>   1.508</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.355</td> <th>  Jarque-Bera (JB):  </th> <td>   1.716</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.660</td> <th>  Prob(JB):          </th> <td>   0.424</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.437</td> <th>  Cond. No.          </th> <td>    38.0</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:             final_test   R-squared:                       0.756\n",
       "Model:                            OLS   Adj. R-squared:                  0.727\n",
       "Method:                 Least Squares   F-statistic:                     26.35\n",
       "Date:                Fri, 19 Feb 2021   Prob (F-statistic):           6.19e-06\n",
       "Time:                        20:15:55   Log-Likelihood:                -73.497\n",
       "No. Observations:                  20   AIC:                             153.0\n",
       "Df Residuals:                      17   BIC:                             156.0\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     -1.8709     11.635     -0.161      0.874     -26.420      22.678\n",
       "quiz           6.4289      0.956      6.725      0.000       4.412       8.446\n",
       "sleep_time     4.1917      1.778      2.357      0.031       0.440       7.943\n",
       "==============================================================================\n",
       "Omnibus:                        2.073   Durbin-Watson:                   1.508\n",
       "Prob(Omnibus):                  0.355   Jarque-Bera (JB):                1.716\n",
       "Skew:                           0.660   Prob(JB):                        0.424\n",
       "Kurtosis:                       2.437   Cond. No.                         38.0\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# statsmodels로 회귀분석 수행\n",
    "formula = 'final_test ~ quiz + sleep_time'\n",
    "result = smf.ols(formula, df).fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 중회귀모형의 회귀계수 -> Numpy\n",
    "x1 = df['quiz']\n",
    "x2 = df['sleep_time']\n",
    "\n",
    "y = df['final_test']\n",
    "p = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $\\beta_0,\\beta_1,\\beta_2$의 추정값인 $\\hat{\\beta_0},\\hat{\\beta_1},\\hat{\\beta_2}$을 구하기\n",
    "* 단순회귀모형의 경우와 마찬가지로 첫 번째 열은 전부 1, 두 번째 열은 x1, 세 번째 열은 x2가 되는 행렬 X를 생성하고, 최소제곱법을 실행함으로써 구할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-20-ac660600ab5e>:2: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  beta0_hat, bta1_hat, beta2_hat = np.linalg.lstsq(X,y)[0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-1.8709143470996081, 6.553732606043085, 4.191706546398686)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([np.ones_like(x1),x1,x2]).T\n",
    "beta0_hat, bta1_hat, beta2_hat = np.linalg.lstsq(X,y)[0]\n",
    "beta0_hat, beta1_hat, beta2_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $\\hat{\\beta_0},\\hat{\\beta_1},\\hat{\\beta_2}$을 활용하여 예측값 $\\hat{y_i} = {\\hat{\\beta_0}} + {\\hat{\\beta_1}x_{i1}} + {\\hat{\\beta_2}x_{2i}}$와 $\\hat{\\epsilon_i} = {y_i} - {\\hat{y_i}}$을 구하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     11.164950\n",
       "1     -7.430442\n",
       "2     -1.345130\n",
       "3    -11.293888\n",
       "4     -4.397484\n",
       "5      4.115585\n",
       "6     -5.605516\n",
       "7     -1.672317\n",
       "8     -5.045037\n",
       "9     -9.957041\n",
       "10    -4.098271\n",
       "11     2.757432\n",
       "12   -14.931862\n",
       "13     6.628657\n",
       "14    18.401190\n",
       "15    12.744861\n",
       "16    -1.739196\n",
       "17   -10.429446\n",
       "18    -6.490308\n",
       "19    19.421503\n",
       "dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = beta0_hat + beta1_hat*x1 + beta2_hat*x2\n",
    "eps_hat = y - y_hat\n",
    "eps_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 표준오차도 단순회귀모형의 경우와 동일\n",
    "s_var = np.sum(eps_hat**2) / (n-p-1)\n",
    "C0, C1, C2 = np.diag(np.linalg.pinv(np.dot(X.T,X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4340116832867875, 7.9494014095105845)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 이것들을 활용하여 수면시간에 대한 계숭인 beta2의 95% 신뢰구간을 구해본다\n",
    "rv = stats.t(n-p-1)\n",
    "\n",
    "lcl = beta2_hat - rv.isf(0.025) * np.sqrt(s_var*C2)\n",
    "hcl = beta2_hat - rv.isf(0.975) * np.sqrt(s_var*C2)\n",
    "lcl,hcl # statsmodels의 결과와 일치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>final_test</td>    <th>  R-squared:         </th> <td>   0.782</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.724</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   13.46</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 19 Feb 2021</td> <th>  Prob (F-statistic):</th> <td>7.47e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>20:15:55</td>     <th>  Log-Likelihood:    </th> <td> -72.368</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    20</td>      <th>  AIC:               </th> <td>   154.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    15</td>      <th>  BIC:               </th> <td>   159.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "            <td></td>               <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>             <td>    1.3330</td> <td>   12.434</td> <td>    0.107</td> <td> 0.916</td> <td>  -25.169</td> <td>   27.835</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>school_method[T.bus]</th>  <td>   -1.8118</td> <td>    6.324</td> <td>   -0.286</td> <td> 0.778</td> <td>  -15.292</td> <td>   11.668</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>school_method[T.walk]</th> <td>   -7.6555</td> <td>    6.420</td> <td>   -1.192</td> <td> 0.252</td> <td>  -21.339</td> <td>    6.028</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>quiz</th>                  <td>    6.0029</td> <td>    1.033</td> <td>    5.809</td> <td> 0.000</td> <td>    3.800</td> <td>    8.206</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sleep_time</th>            <td>    4.5238</td> <td>    1.809</td> <td>    2.501</td> <td> 0.024</td> <td>    0.668</td> <td>    8.380</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 1.764</td> <th>  Durbin-Watson:     </th> <td>   1.418</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.414</td> <th>  Jarque-Bera (JB):  </th> <td>   0.989</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.545</td> <th>  Prob(JB):          </th> <td>   0.610</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.985</td> <th>  Cond. No.          </th> <td>    41.8</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:             final_test   R-squared:                       0.782\n",
       "Model:                            OLS   Adj. R-squared:                  0.724\n",
       "Method:                 Least Squares   F-statistic:                     13.46\n",
       "Date:                Fri, 19 Feb 2021   Prob (F-statistic):           7.47e-05\n",
       "Time:                        20:15:55   Log-Likelihood:                -72.368\n",
       "No. Observations:                  20   AIC:                             154.7\n",
       "Df Residuals:                      15   BIC:                             159.7\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=========================================================================================\n",
       "                            coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------------\n",
       "Intercept                 1.3330     12.434      0.107      0.916     -25.169      27.835\n",
       "school_method[T.bus]     -1.8118      6.324     -0.286      0.778     -15.292      11.668\n",
       "school_method[T.walk]    -7.6555      6.420     -1.192      0.252     -21.339       6.028\n",
       "quiz                      6.0029      1.033      5.809      0.000       3.800       8.206\n",
       "sleep_time                4.5238      1.809      2.501      0.024       0.668       8.380\n",
       "==============================================================================\n",
       "Omnibus:                        1.764   Durbin-Watson:                   1.418\n",
       "Prob(Omnibus):                  0.414   Jarque-Bera (JB):                0.989\n",
       "Skew:                           0.545   Prob(JB):                        0.610\n",
       "Kurtosis:                       2.985   Cond. No.                         41.8\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# statsmodels은 질적변수를 가변수로 변환하는 것을 자동으로 처리해줌\n",
    "formula = 'final_test ~ quiz + sleep_time + school_method'\n",
    "result = smf.ols(formula, df).fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 모형의 선택\n",
    "* '좋은 모형'? $\\rightarrow$ '적합이 좋은 것' & '예측이 좋은 것'\n",
    "* 적합이 좋은 것 = 모형이 주변에 있는 데이터에 어느 정도 들어맞는다는 것\n",
    "  - 회귀직선이 데이터에 완전하게 들어맞고 잔차가 작으면 그 모형은 좋은 모형이라고 할 수 있음\n",
    "* 예측이 좋은 것 = 주변에 있는 데이터로 만든 모형이 미지의 데이터를 어느 정도 예측할 수 있다는 것\n",
    "  - 모르는 데이터의 설명변수라도 모형이 반응변수를 정확하게 예측할 수 있다면 그것은 좋은 모형이라고 할 수 있음\n",
    "* 적합이 좋다는 것은 설명변수를 증가시켜 가는 것만으로 간단하게 달성됨\n",
    "  - 그러나 이렇게 만든 모형은 일반적으로 예측정확도가 떨어짐 $\\rightarrow$ 과적합(overfitting; 맹 복잡한 모형은 표현력이 너무 높은 나머지 주변 데이터에 지나치게 적합되어 일반적인 예측성을 잃어버리는 것)\n",
    "  - 이 때문에 모형을 고를 때는 보통 적합도가 좋은 것보다 예측 정확도가 좋은 것을 고르게 됨\n",
    "* 결정계수(R-squared): 모형의 데이터에 대한 적합도를 나타내는 기본적인 지표\n",
    "  - 흔히 $R^2$로 표기하고 statsomdels의 결과에는 R-squared로 출력되어 있음\n",
    "  - 0과 1 사이의 값을 취하고, 1에 가까울수록 모델은 데이터에 잘 들어맞는다고 생각할 수 있음\n",
    "  - 결정계수를 구하려면 총변동, 회귀변동, 잔차변동을 알아야 함\n",
    "    + 총변동(total variation): 관측값 $y_i$가 어느 정도 분산되어 있는지를 나타내는 지표\n",
    "      * $\\sum_{i=1}^n{({y_i} - \\bar{y})}^2$으로 계산\n",
    "    + 회귀변동(regression variation): 예측값 $\\hat{y_i}$가 관측값의 평균값 $\\bar{y}$에 대해서 어느 정도 분산되어 있는질르 나타내는 지표\n",
    "      * $\\sum_{i=1}^n{({\\hat{y_i}} - \\bar{y})}^2$으로 계산, 예측값 $\\hat{y_i}$가 관측값 $y_i$에 가까울수록 총변동에 가까워짐\n",
    "    + 잔차변동(residual variation): 잔차의 산포도를 나타내는 지표\n",
    "      * $\\sum_{i=1}^n{\\hat{\\epsilon}}^2$으로 계산, 잔차제곱합과 동일, 예측값 $\\hat{y_i}$가 관측값 $y_i$에 가까울수록 0에 가까워짐\n",
    "  - 위의 세 가지 변동에는 $총변동 = 회귀변동 + 잔차변동$의 관계 성립\n",
    "  - 예측값 $\\hat{y_i}$가 관측값 $y_i$에 가까울수록 총변동에 가까워짐 $\\rightarrow$ 총변동 중 회귀변동이 차지하는 비율이 클수록 좋은 모형이라고 할 수 있음\n",
    "  - 그러므로 결정계수는 다음과 같이 계산: $R^2 = {회귀변동 \\over 총변동} = {1 - {잔차변동 \\over 총변동}}$\n",
    "* 조정결정계수(adjusted R-squared): 설명변수를 추가했을 때 그 설명변수에 어느 정도 이상의 설명력이 없는 경우 결정계수의 값이 증가하지 않도록 조정하는 결정계수\n",
    "  - $\\bar{R^2}$으로 표기, statsmodels의 분석 결과에는 Adj. R-squared로 출력\n",
    "  - 자유조정결정계수라고도 함(자유도를 고려한 결정계수)\n",
    "  - $\\bar{R^2} = 1 - {{잔차변동 / {n-p-1}} \\over {총변동 / {n-1}}}$\n",
    "  - 총변동의 자유도는 회귀계수의 수에 상관없이 항상 n-1이 됨\n",
    "  - 잔차변동의 자유도는 n-p-1, 회귀변동의 자유도는 회귀계수의 수가 됨\n",
    "  - 자유도에 관해서도 $총변동의 자유도 = 회귀변동의 자유도 + 잔차변동의 자유도$를 만족\n",
    "  - 회귀변동의 자유도는 모형의 자유도라고도 부름, statsmodels의 분석 결과에는 Df Model로 출력\n",
    "  - 잔차변동의 자유도는 잔차의 자유도라고도 부름, statsmodels의 분석 결과에는 Df Residual로 출력\n",
    "* F검정(F test): 절편 $\\beta_0$ 이외의 회귀계수에 관해서 다음과 같은 가설로 수행되는 검정\n",
    "  - 귀무가설: $\\beta_1 = \\beta_2 = \\dots = \\beta_p = 0$\n",
    "  - 대립가설: 적어도 하나의 $\\beta_1$은 0이 아니다\n",
    "  - F 검정은 t 검정과 같이 개개의 회귀계수에 대해서가 아닌 모형 전체에 대해서 수행 \n",
    "  - F 검정통계량은 statsmodels 분석결과의 F-statistic에, 그 p값은 Prob(F-stastic)에 출력됨\n",
    "  - F 검정통계량 계산 $\\rightarrow$ 자유도가 (p, n-p-1)인 F 검정을 따름\n",
    "    + ${F} = {{회귀변동/p} \\over {잔차변동/(n-p-1)}}$\n",
    "  - F 검정은 모형의 적합도가 좋을수록 잔차변동보다 회귀변동이 커지는 것을 이용함 (회귀분석의 경우와 비슷)\n",
    "  - 이에 따라 F 검정통계량이 어떤 값보다 커진 경우, 모형이 데이터에 적합되어 있다고 생각할 수 있음\n",
    "  - F 검정통계량의 분모와 분자 $\\rightarrow$ 각각 잔차변동을 그 자유도로 나눈 것과 회귀변동을 그 자유도로 나눈 것\n",
    "    + 각각 잔차의 분산과 모형의 분산이라고 생각할 수 있고, F 검정통계량은 분산의 비를 검정하고 있다고 해석할 수 있음\n",
    "    + 그래서 이 검정을 분산분석(ANOVA, analysis of variance)라고도 부름"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>final_test</td>    <th>  R-squared:         </th> <td>   0.676</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.658</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   37.61</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 19 Feb 2021</td> <th>  Prob (F-statistic):</th> <td>8.59e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>20:15:56</td>     <th>  Log-Likelihood:    </th> <td> -76.325</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    20</td>      <th>  AIC:               </th> <td>   156.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    18</td>      <th>  BIC:               </th> <td>   158.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   23.6995</td> <td>    4.714</td> <td>    5.028</td> <td> 0.000</td> <td>   13.796</td> <td>   33.603</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>quiz</th>      <td>    6.5537</td> <td>    1.069</td> <td>    6.133</td> <td> 0.000</td> <td>    4.309</td> <td>    8.799</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 2.139</td> <th>  Durbin-Watson:     </th> <td>   1.478</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.343</td> <th>  Jarque-Bera (JB):  </th> <td>   1.773</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.670</td> <th>  Prob(JB):          </th> <td>   0.412</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.422</td> <th>  Cond. No.          </th> <td>    8.32</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:             final_test   R-squared:                       0.676\n",
       "Model:                            OLS   Adj. R-squared:                  0.658\n",
       "Method:                 Least Squares   F-statistic:                     37.61\n",
       "Date:                Fri, 19 Feb 2021   Prob (F-statistic):           8.59e-06\n",
       "Time:                        20:15:56   Log-Likelihood:                -76.325\n",
       "No. Observations:                  20   AIC:                             156.7\n",
       "Df Residuals:                      18   BIC:                             158.6\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     23.6995      4.714      5.028      0.000      13.796      33.603\n",
       "quiz           6.5537      1.069      6.133      0.000       4.309       8.799\n",
       "==============================================================================\n",
       "Omnibus:                        2.139   Durbin-Watson:                   1.478\n",
       "Prob(Omnibus):                  0.343   Jarque-Bera (JB):                1.773\n",
       "Skew:                           0.670   Prob(JB):                        0.412\n",
       "Kurtosis:                       2.422   Cond. No.                         8.32\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 단순회귀분석 결과의 출력을 예로 들어 statsmodels의 분석 결과를 보는 방법 & 지표가 어떻게 계산되어 있는지를 살펴본다\n",
    "x = np.array(df['quiz'])\n",
    "y = np.array(df['final_test'])\n",
    "p = 1\n",
    "\n",
    "formula = 'final_test ~ quiz'\n",
    "result = smf.ols(formula, df).fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([51.225, 70.886, 23.699, 43.361, 33.53 , 29.598, 36.152, 46.638,\n",
       "       49.914, 59.09 , 51.225, 68.92 , 36.807, 81.372, 25.666, 67.61 ,\n",
       "       51.225, 60.4  , 32.875, 36.807])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모형의 예측값과 잔차가 필요\n",
    "# result의 fittedvalues라는 인스턴스 변수에 Series 형태로 저장되어 있는 예측값 불러오기\n",
    "y_hat = np.array(result.fittedvalues)\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 15.775,   0.114,  -4.699,  -8.361,   1.47 ,  10.402, -13.152,\n",
       "        -9.638, -10.914,  -4.09 , -11.225,   1.08 ,  -7.807,   6.628,\n",
       "        21.334,   9.39 ,   0.775,  -5.4  , -14.875,  23.193])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 잔차는 resid에 저장되어 있으며 마찬가지로 Series 형태\n",
    "eps_hat = np.array(result.resid)\n",
    "eps_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 모형 적합도를 측정하는 지표 중 하나로 회귀직선을 구하기 위해 사용한 잔차제곱합을 고려\n",
    "  - 잔차제곱합은 데이터와 회귀직선의 적합도를 나타내는 지표기 때문"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2417.227825229262"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(eps_hat**2) # 이 값을 보고 적합도가 좋은 지를 알기 힘듦 -> 다른 모형과 비교할 때 사용할 수 있는 지표에 어떤 것이 있을까"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결정계수 구하기\n",
    "total_var = np.sum((y - np.mean(y))**2)\n",
    "exp_var = np.sum((y_hat - np.mean(y))**2)\n",
    "unexp_var = np.sum(eps_hat**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7468.55, 7468.549999999999)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 관계식 성립 확인\n",
    "total_var, exp_var + unexp_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6763457665505"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_var / total_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 단순회귀의 결정계수는, 설명변수와 반응변수의 상관계수 제곱 $r_{xy}^2$와 일치함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6763457665505004"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(x,y)[0,1]**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6583649758033057"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 단순회귀모형의 조정결정계수 구현\n",
    "1 - (unexp_var / (n-p-1)) / (total_var / (n-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37.61490671126525"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# F 검정통계량\n",
    "f = (exp_var/p) / (unexp_var/(n-p-1))\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.590875866687497e-06"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 대응하는 p값 구하기\n",
    "rv = stats.f(p,n-p-1)\n",
    "1 - rv.cdf(f) # 귀무가설 기각, 설명변수 중 적어도 하나는 반응변수에 영향을 주는 것을 알 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 최대로그우도와 AIC\n",
    "  - 아카이케의 정보량 기준(AIC, Akaike's information criterion) $\\rightarrow$  모형의 예측 성능에 관한 중요한 지표\n",
    "  - AIC를 설명하기 위해선 우도 및 최대로그우도를 알아야 함\n",
    "    + 우도(likelihood): 어떤 관측값을 얻을 확률"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.030870000000000005"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 우도\n",
    "# 0.3의 확률로 앞면, 0.7의 확률로 뒷면이 나오는 동전을 고려\n",
    "prob = 0.3\n",
    "coin_result = [0,1,0,0,1]\n",
    "\n",
    "rv = stats.bernoulli(prob)\n",
    "L = np.prod(rv.pmf(coin_result))\n",
    "L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 모수 p를 알지 못할 때 우도 $L$은 $p$에 대한 함수로 표현됨\n",
    "* 이를 우도함수(likelihood function)이라고 함 $\\rightarrow$ $L(p)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# p를 0에서 1로 변화시킬 때의 우도함수\n",
    "ps = np.linspace(0,1,100)\n",
    "Ls = [np.prod(stats.bernoulli(prob).pmf(coin_result)) for prob in ps]\n",
    "\n",
    "fig = plt.figure(figsize=(10,6))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(ps, Ls, label='likelihood function', color='gray')\n",
    "ax.legend(fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 우도함수는 p=0.4일 때 최대가 되는 거 같음 $\\rightarrow$ 관측값에 의해 p=0.4가 가장 그럴 듯한 모수라는 뜻\n",
    "* 관측값에서 가장 그럴 듯하다는 이유로 모수 $p$를 추정하는 방법 = 최우추정법(method of maximum likelihood)\n",
    "  - 최우추정법에 의해 추측되는 추정량 = 최우추정량(maximum likelihood estimator), 그 추정값 = 최우추정값(maximum likelihood estimate)\n",
    "* $f(x)$가 이산형 확률변수에서는 확률함수, 연속형 확률변수에서는 확률밀도함수라고 할 떄,\n",
    "  - $L = \\prod_{i=1} f(x_i)$\n",
    "* 우도는 확률의 곱이 되므로 곱하면 곱할수록 0에 가까워짐\n",
    "  - 이와 같은 작은 값은 손으로도, 컴퓨터로도 다루기 힘듦 $\\rightarrow$ 우도에 로그를 취한 로그우도(log-likelihood)가 대신 사용되기도 함\n",
    "  - $\\log{L} = {\\sum_{i=1} \\log{f(x_i)}}$\n",
    "* 우도함수가 최대로 될 때 로그우도함수도 최대가 되므로, 최우추정은 로그우도함수가 최대가 될 때의 파라미터로서 구할 수 있음\n",
    "  - 그 때의 로그우도의 값을 최대로그우도(maximum log-likelihood)라고 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.365058335046282"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 동전의 최대로그우도 구하기\n",
    "# p의 최우추정값은 0.4였으므로 p=0.4일 때 로그우도는 최대로그우도가 됨\n",
    "prob = 0.4\n",
    "rv = stats.bernoulli(prob)\n",
    "mll = np.sum(np.log(rv.pmf([0,1,0,0,1])))\n",
    "mll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 다시 회귀분석으로 돌아와서...\n",
    "  - 단순회귀모형에서 $Y_i \\sim N({{\\beta_0} + {\\beta_1 x_1}}, {\\sigma^2})$이라고 가정했을 때\n",
    "  - 이 가정을 토대로 관측값 $(x_1,y_1),(x_2,y_2),\\cdots,(x_n,y_n)$에 대한 최대로그우도는 모형의 데이터에 대한 적합이 좋다는 것을 나타낸다고 생각할 수 있음\n",
    "  - 최대로그우도는 분석 결과의 Log-likelihood에 출력됨\n",
    "* 단순회귀모형의 최대로그우도\n",
    "  - 단순회귀모형에서 ${\\beta_0},{\\beta_1},{\\sigma^2}$의 최우추정량은 각각 ${\\hat{\\beta_0}},{\\hat{\\beta_1}},{{1 \\over n}\\sum_{i=1}^n {\\hat{\\epsilon_i}}}$가 됨\n",
    "  - 최대로그우도는 파라미터를 최우추정량으로 했을 때의 관측값의 로그우도였으므로 최대로그우도는 $N({\\hat{y}},{{1 \\over n}\\sum_{i=1}^n {\\hat{\\epsilon_i}}}$의 밀도함수를 $f(x)$로 하여 $\\sum_{i=1}^n {\\log{f(y_i)}}$가 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-76.32521428624038"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rv = stats.norm(y_hat, np.sqrt(unexp_var / n))\n",
    "mll = np.sum(np.log(rv.pdf(y)))\n",
    "mll # 최대로그우도 역시 설명변수를 늘리면 값이 증가하는 특징이 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* AIC\n",
    "  - 로그우도는 모형의 적합도를 나타내지만 그 지표는 의미 없는 설명변수를 늘림으로써 값이 증가함\n",
    "  - 그러므로 로그우도와 같이 적합도를 기준으로 하면 일반 성능이 나쁜 모형이 선택됨\n",
    "  - 이 때문에 모형의 복잡도(설명변수의 수)와 데이터에 대한 적합도의 균형을 잡는 지표가 필요 $\\rightarrow$ AIC\n",
    "  - AIC는 일반적인 성능도 고려하여 넣은 지표이므로 예측이 좋은 것을 나타내는 지표라고 할 수 있음\n",
    "  - AIC를 구하는 방식은 다양함, 그 중에서 statsmodels의 출력에 맞추어 정의하면 $\\rightarrow$ $AIC = -2 \\times 최대로그우도 + 2 \\times 회귀계수의 수$\n",
    "  - AIC는 최대로그우도에 회귀계수의 수를 페널티로 부가하여 무턱대고 설명변수를 늘린 모형이 좋은 모형으로 선택되지 않게끔 한다고 해석할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156.65042857248076"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AIC 구하기\n",
    "aic = -2 * mll + 2 * (p+1)\n",
    "aic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* AIC는 값이 작을수록 모형의 예측 정확도가 좋다고 생각할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* BIC(Bayesian information criterion; 베이지안 정보 기준)\n",
    "  - AIC와 유사함\n",
    "  - 회귀계수의 수에 더해 표본 크기 n에 대해서도 페널티를 부과한 것\n",
    "  - $BIC = -2 \\times 최대로그우도 + \\log{n} \\times 회귀계수의 수$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158.64189311958876"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BIC 구하기\n",
    "bic = -2 * mll + np.log(n) * (p+1)\n",
    "bic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* BIC 역시 AIC와 같이 값이 작을수록 모형의 예측 정확도가 좋다고 생각할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. 모형의 타당성\n",
    "* 모형의 타당성: 처음에 회귀분석에 관해서 세운 '오차항 $\\epsilon_i$는 서로 독립이고 $N(0,\\sigma^2$을 따른다'라는 가정을 만족하고 있는지 여부를 체크하는 것\n",
    "* 정규성 검정: 오차항 $\\epsilon_i$가 $N(0,\\sigma^2)$을 따른다는 가정이 타당했는지 알아보기 위해, 잔차 $\\hat{\\epsilon_i}$가 정규분포를 따르고 있는지를 확인하는 것\n",
    "  - statsomdels에서는 정규성 검정으로 Omnibus 검정과 Jarque-Bera 검정이 사용됨\n",
    "  - 정규성 검정은... 귀무가설: 잔차항은 정규분포를 따른다 / 대립가설: 잔차항은 정규분포를 따르지 않는다 ... 라는 가설검정 수행\n",
    "  - 이러한 검정의 p값인 Prob(Omnibus)나 Prob(JB)가 유의수준인 0.05보다 크면 문제될 게 없음\n",
    "  - Skew: 왜도, Kurtosis: 첨도 $\\rightarrow$ 평균이나 분산과 마찬가지로 데이터의 특징을 나타내는 지표\n",
    "  - 왜도와 첨도를 통해 정규성을 확인할 수 있음\n",
    "  - 왜도(skewness): 분포의 좌우대칭을 측정하는 지표 $\\rightarrow$ $\\sum_i^n({{x-\\bar{x}} \\over {S}})^3$\n",
    "    + 왜도는 정규분포와 같이 좌우대칭인 분포이면 0이 되고, 카이제곱분포와 같이 왼쪽으로 치우친 분포이면 0보다 크고, 반대로 오른쪽으로 치우친 분포일 때에는 0보다 작은 값이 됨\n",
    "    + stats.skew로 계산할 수 있음\n",
    "  - 첨도(kurtosis): 분포의 뽀족한 정도를 측정하는 지표 $\\rightarrow$ $\\sum_i^n({{x-\\bar{x}} \\over {S}})^4$\n",
    "    + 첨도는 정규분포일 때 3이 되고, 정규분포보다 뾰족한 정점을 가진 분포라면 3보다 크고, 정규분포보다 둥근 정점을 가진 분포라면 3보다 작은 값이 됨\n",
    "    + stats.kurtosis의 인수 fisher를 False로 함으로써 정의할 수 있음\n",
    "* 더빈-왓슨비(Durbin-Watson ratio): 다른 오차항이 서로 무상관인지 여부를 체크하는 지표\n",
    "  - 다루고 있는 데이터가 시계열 데이터인 경우에 특히 중요\n",
    "  - $\\sum_{i=2}^n({{\\hat{\\epsilon_i} - {\\hat{\\epsilon_{i-1}}}}})^2 \\over {\\sum_{i=1}^n{\\hat{\\epsilon_i}}^2}$\n",
    "  - 더빈-왓슨비는 0부터 4의 값이 되고, 0에 가까우면 양의 상관, 4에 가까우면 음의 상관, 2 앞뒤의 값이면 무상관이라고 판단\n",
    "* 다중공선성: 조건수(Cond. No.)로 체크\n",
    "  - 조건수의 값이 크면 다중공선성과 설명변수 사이에 강한 상관이 생겼다는 것을 의미\n",
    "  - 다중공선성이 크면 회귀계수의 분산이 커져 모형의 예측 결과가 나빠진다고 알려져 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>final_test</td>    <th>  R-squared:         </th> <td>   0.756</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.727</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   26.35</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 19 Feb 2021</td> <th>  Prob (F-statistic):</th> <td>6.19e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>20:15:57</td>     <th>  Log-Likelihood:    </th> <td> -73.497</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    20</td>      <th>  AIC:               </th> <td>   153.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    17</td>      <th>  BIC:               </th> <td>   156.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>  <td>   -1.8709</td> <td>   11.635</td> <td>   -0.161</td> <td> 0.874</td> <td>  -26.420</td> <td>   22.678</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>quiz</th>       <td>    6.4289</td> <td>    0.956</td> <td>    6.725</td> <td> 0.000</td> <td>    4.412</td> <td>    8.446</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sleep_time</th> <td>    4.1917</td> <td>    1.778</td> <td>    2.357</td> <td> 0.031</td> <td>    0.440</td> <td>    7.943</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 2.073</td> <th>  Durbin-Watson:     </th> <td>   1.508</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.355</td> <th>  Jarque-Bera (JB):  </th> <td>   1.716</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.660</td> <th>  Prob(JB):          </th> <td>   0.424</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.437</td> <th>  Cond. No.          </th> <td>    38.0</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:             final_test   R-squared:                       0.756\n",
       "Model:                            OLS   Adj. R-squared:                  0.727\n",
       "Method:                 Least Squares   F-statistic:                     26.35\n",
       "Date:                Fri, 19 Feb 2021   Prob (F-statistic):           6.19e-06\n",
       "Time:                        20:15:57   Log-Likelihood:                -73.497\n",
       "No. Observations:                  20   AIC:                             153.0\n",
       "Df Residuals:                      17   BIC:                             156.0\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     -1.8709     11.635     -0.161      0.874     -26.420      22.678\n",
       "quiz           6.4289      0.956      6.725      0.000       4.412       8.446\n",
       "sleep_time     4.1917      1.778      2.357      0.031       0.440       7.943\n",
       "==============================================================================\n",
       "Omnibus:                        2.073   Durbin-Watson:                   1.508\n",
       "Prob(Omnibus):                  0.355   Jarque-Bera (JB):                1.716\n",
       "Skew:                           0.660   Prob(JB):                        0.424\n",
       "Kurtosis:                       2.437   Cond. No.                         38.0\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 앞전에 AIC를 기준으로 좋은 모형이라고 판단된 모형 (설명변수에 쪽지 시험과 수면 시간을 사용한 중회귀모형의 결과를 사용함)\n",
    "formula = 'final_test ~ quiz + sleep_time'\n",
    "result = smf.ols(formula, df).fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 오차항 $\\epsilon_i$에 관한 체크이므로, 분석 대상이 되는 것은 잔차 $\\hat{\\epsilon_i}$임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 11.689,  -6.531,  -1.345, -10.919,  -4.21 ,   4.228,  -5.368,\n",
       "        -1.235,  -4.546,  -9.283,  -3.574,   3.619, -14.682,   7.727,\n",
       "        18.439,  13.581,  -1.215,  -9.73 ,  -6.316,  19.671])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eps_hat = np.array(result.resid)\n",
    "eps_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.660"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 왜도\n",
    "stats.skew(eps_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.437"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 첨도\n",
    "stats.kurtosis(eps_hat, fisher=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5082185264423011"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 더빈-왓슨비\n",
    "np.sum(np.diff(eps_hat,1)**2) / np.sum(eps_hat**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quiz</th>\n",
       "      <th>final_test</th>\n",
       "      <th>sleep_time</th>\n",
       "      <th>school_method</th>\n",
       "      <th>mid_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.2</td>\n",
       "      <td>67</td>\n",
       "      <td>7.2</td>\n",
       "      <td>bus</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.2</td>\n",
       "      <td>71</td>\n",
       "      <td>7.9</td>\n",
       "      <td>bicycle</td>\n",
       "      <td>14.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>19</td>\n",
       "      <td>5.3</td>\n",
       "      <td>bus</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>35</td>\n",
       "      <td>6.8</td>\n",
       "      <td>walk</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.5</td>\n",
       "      <td>35</td>\n",
       "      <td>7.5</td>\n",
       "      <td>walk</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   quiz  final_test  sleep_time school_method  mid_test\n",
       "0   4.2          67         7.2           bus       8.4\n",
       "1   7.2          71         7.9       bicycle      14.4\n",
       "2   0.0          19         5.3           bus       0.0\n",
       "3   3.0          35         6.8          walk       6.0\n",
       "4   1.5          35         7.5          walk       3.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 다중공선성\n",
    "# 쪽지 시험의 결과의 2배인 중간고사라는 변수를 추가\n",
    "# 쪽지 시험과 중간고사의 상관관계는 1이 되고 이 데이터는 큰 다중공선성을 가짐\n",
    "df['mid_test'] = df['quiz']*2\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>final_test</td>    <th>  R-squared:         </th> <td>   0.676</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.658</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   37.61</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 19 Feb 2021</td> <th>  Prob (F-statistic):</th> <td>8.59e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>20:15:57</td>     <th>  Log-Likelihood:    </th> <td> -76.325</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    20</td>      <th>  AIC:               </th> <td>   156.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    18</td>      <th>  BIC:               </th> <td>   158.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   23.6995</td> <td>    4.714</td> <td>    5.028</td> <td> 0.000</td> <td>   13.796</td> <td>   33.603</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>quiz</th>      <td>    1.3107</td> <td>    0.214</td> <td>    6.133</td> <td> 0.000</td> <td>    0.862</td> <td>    1.760</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mid_test</th>  <td>    2.6215</td> <td>    0.427</td> <td>    6.133</td> <td> 0.000</td> <td>    1.723</td> <td>    3.519</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 2.139</td> <th>  Durbin-Watson:     </th> <td>   1.478</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.343</td> <th>  Jarque-Bera (JB):  </th> <td>   1.773</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.670</td> <th>  Prob(JB):          </th> <td>   0.412</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.422</td> <th>  Cond. No.          </th> <td>1.30e+16</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 1.16e-29. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:             final_test   R-squared:                       0.676\n",
       "Model:                            OLS   Adj. R-squared:                  0.658\n",
       "Method:                 Least Squares   F-statistic:                     37.61\n",
       "Date:                Fri, 19 Feb 2021   Prob (F-statistic):           8.59e-06\n",
       "Time:                        20:15:57   Log-Likelihood:                -76.325\n",
       "No. Observations:                  20   AIC:                             156.7\n",
       "Df Residuals:                      18   BIC:                             158.6\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     23.6995      4.714      5.028      0.000      13.796      33.603\n",
       "quiz           1.3107      0.214      6.133      0.000       0.862       1.760\n",
       "mid_test       2.6215      0.427      6.133      0.000       1.723       3.519\n",
       "==============================================================================\n",
       "Omnibus:                        2.139   Durbin-Watson:                   1.478\n",
       "Prob(Omnibus):                  0.343   Jarque-Bera (JB):                1.773\n",
       "Skew:                           0.670   Prob(JB):                        0.412\n",
       "Kurtosis:                       2.422   Cond. No.                     1.30e+16\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 1.16e-29. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formula = 'final_test ~ quiz + mid_test'\n",
    "result = smf.ols(formula, df).fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 조건수가 매우 큰 값이 됨\n",
    "  - 이처럼 다중공선성이 생기면 조건수는 매우 큰 값이 됨\n",
    "  - 조건수가 꽤 큰 값이 되어 있을 때는 다중공선성을 의심해보는 것이 좋음\n",
    "  - 그 경우에는 설명변수 중에서 한쪽 변수를 모형에서 제외하는 것을 해결책으로 생각할 수 있음"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
